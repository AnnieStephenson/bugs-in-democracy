{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "from rcv_distribution import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_learning/rcv_dimensionality.py:170: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 89669,\n",
       " 0.47423947404876676: 11600,\n",
       " 1.4136378554535023: 579,\n",
       " 3.0: 51673,\n",
       " 2.192155473835831: 948,\n",
       " 0.3167198370337414: 2801,\n",
       " 0.41511902958066277: 2748,\n",
       " 0.75: 3337,\n",
       " 0.5333599185168707: 398,\n",
       " 2.0540728885103365: 4401,\n",
       " 0.5135182221275841: 2767,\n",
       " 0.6317591110637921: 652,\n",
       " 1.5027386629065809: 1087,\n",
       " 1.2668793481349656: 2180,\n",
       " 2.2905546663827523: 1131,\n",
       " 1.7001595111012242: 291,\n",
       " 2.03379555531896: 181,\n",
       " 1.5819186221650163: 290,\n",
       " 1.3053178147119375: 179,\n",
       " 1.5417995925843535: 68,\n",
       " 1.4636777332288085: 528}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Maine_11062018_CongressionalDistrict2.csv\")\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9173969066559533"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Maine_11062018_CongressionalDistrict2.csv\")\n",
    "\n",
    "# Create a list of data points\n",
    "data_points = []\n",
    "for key, value in points.items():\n",
    "    data_points.extend([key] * value)\n",
    "\n",
    "# Convert to numpy array\n",
    "data_points = np.array(data_points)\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "g = skew(data_points)\n",
    "k = kurtosis(data_points)\n",
    "\n",
    "# Calculate bimodality coefficient\n",
    "n = len(data_points)\n",
    "BC = (g**2 + 1) / (k + 3 * (n-1)**2 / ((n-2) * (n-3)))\n",
    "\n",
    "BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eric Simpson\\Repository\\bugs-in-democracy\\rcv_learning\\playground.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m csv_files \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(\u001b[39m\"\u001b[39m\u001b[39m../rcv_elections_database/**/*.csv\u001b[39m\u001b[39m\"\u001b[39m, recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, file_path \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(csv_files):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Get the consistency points for the election\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     points \u001b[39m=\u001b[39m get_consistency_points(file_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# Create a list of data points\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eric%20Simpson/Repository/bugs-in-democracy/rcv_learning/playground.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     data_points \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Eric Simpson\\Repository\\bugs-in-democracy\\rcv_learning\\rcv_distribution.py:181\u001b[0m, in \u001b[0;36mget_consistency_points\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_consistency_points\u001b[39m(file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[0;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m    Performs RCV analysis and normalizes the distances of MDS-1D coordinates,\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m    then calculates the consistency of each ballot and collects points based on this consistency.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m        a list of candidates in their most consistent permutation, and a list of mds-1d coordinates.\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m     rcv_and_normalized_results \u001b[39m=\u001b[39m perform_rcv_and_normalize(file)\n\u001b[0;32m    182\u001b[0m     most_consistent_permutation \u001b[39m=\u001b[39m []\n\u001b[0;32m    183\u001b[0m     permutation_numbers \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Eric Simpson\\Repository\\bugs-in-democracy\\rcv_learning\\rcv_dimensionality.py:279\u001b[0m, in \u001b[0;36mperform_rcv_and_normalize\u001b[1;34m(csv_file, n_runs)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39mPerform the ranked-choice-voting (RCV) analysis and normalize the distances of MDS-1D coordinates.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39mReturn a dictionary with candidate names as keys and normalized distances as values.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39m    A dictionary mapping candidate names to normalized MDS-1D coordinates.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m# Perform the RCV analysis\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names \u001b[39m=\u001b[39m perform_rcv_analysis(csv_file, n_runs)\n\u001b[0;32m    281\u001b[0m \u001b[39m# Normalize the distances\u001b[39;00m\n\u001b[0;32m    282\u001b[0m normalized_coordinates_dict \u001b[39m=\u001b[39m get_distances_normalized(most_common_order, mds_1d_coordinates, candidate_names)\n",
      "File \u001b[1;32mc:\\Users\\Eric Simpson\\Repository\\bugs-in-democracy\\rcv_learning\\rcv_dimensionality.py:169\u001b[0m, in \u001b[0;36mperform_rcv_analysis\u001b[1;34m(csv_file, n_runs, random_state, ignore_values, metric)\u001b[0m\n\u001b[0;32m    166\u001b[0m         freq_upper_triangle[j, i] \u001b[39m=\u001b[39m freq_upper_triangle[i, j]\n\u001b[0;32m    168\u001b[0m \u001b[39m# Compute distance metric\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m min_freq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmin(freq_upper_triangle[freq_upper_triangle \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m])\n\u001b[0;32m    170\u001b[0m distance \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msqrt(freq_upper_triangle)\n\u001b[0;32m    171\u001b[0m distance[np\u001b[39m.\u001b[39misnan(distance)] \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m/\u001b[39m min_freq\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2916\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2800\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[0;32m   2801\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2802\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2804\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[0;32m   2805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[0;32m   2915\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2916\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2917\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "# Open the output CSV file\n",
    "with open('bimodality_results.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    writer.writerow(['filename', 'bimodality'])\n",
    "    \n",
    "    # Search for CSV files in the directory and its subdirectories\n",
    "    csv_files = glob.glob(\"../rcv_elections_database/**/*.csv\", recursive=True)\n",
    "\n",
    "    for idx, file_path in enumerate(csv_files):\n",
    "        # Get the consistency points for the election\n",
    "        points = get_consistency_points(file_path)\n",
    "        \n",
    "        # Create a list of data points\n",
    "        data_points = []\n",
    "        for key, value in points.items():\n",
    "            data_points.extend([key] * value)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        data_points = np.array(data_points)\n",
    "\n",
    "        # Calculate skewness and kurtosis\n",
    "        g = skew(data_points)\n",
    "        k = kurtosis(data_points)\n",
    "\n",
    "        # Calculate bimodality coefficient\n",
    "        n = len(data_points)\n",
    "        bimodality = 0.0\n",
    "        try:\n",
    "            bimodality = (g**2 + 1) / (k + 3 * (n-1)**2 / ((n-2) * (n-3)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Write the filename and bimodality coefficient to the CSV\n",
    "        writer.writerow([file_path, bimodality])\n",
    "\n",
    "        # Flush the output after every 10 runs\n",
    "        if idx % 10 == 9:\n",
    "            csvfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Maine_11062018_CongressionalDistrict2.csv\")\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Alaska_11082022_USRepresentative.csv\")\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Alaska_08162022_HouseofRepresentativesSpecial.csv\")\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/Alaska_04102020_PRESIDENTOFTHEUNITEDSTATES.csv\")\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the consistency points for the election\n",
    "points = get_consistency_points(\"../rcv_elections_database/classic/NewYorkCity_06222021_DEMMayorCitywide.csv\")\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
