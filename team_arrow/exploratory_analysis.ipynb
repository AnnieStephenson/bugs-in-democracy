{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the main directory\n",
    "main_dir_path = \"rcv_elections_database/\"\n",
    "\n",
    "# Define the subdirectories\n",
    "subdirectories = [\n",
    "    \"proportional\",\n",
    "    \"sequential\",\n",
    "    \"single\"\n",
    "]\n",
    "\n",
    "# Create a list to store all dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop over all subdirectories\n",
    "for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(main_dir_path, subdir)\n",
    "\n",
    "    # Loop over all the CSV files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Read the CSV file into a DataFrame, adding the low_memory=False option\n",
    "            df = pd.read_csv(os.path.join(subdir_path, filename), low_memory=False)\n",
    "            \n",
    "            # Add new columns 'source_file' and 'type' containing the name of the source CSV file and the type of the election, respectively\n",
    "            df['source_file'] = filename.strip('.csv')\n",
    "            df['type'] = subdir  # This will indicate the type of the election\n",
    "\n",
    "            # Keep only columns that start with 'rank' or are 'source_file' or 'type'\n",
    "            df = df[[col for col in df.columns if col.startswith('rank') or col in ['source_file', 'type']]]\n",
    "\n",
    "            # Append the DataFrame to the list of dataframes\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into a single DataFrame\n",
    "cast_vote_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorder the columns to move the rank columns to the end\n",
    "cols_to_order = ['source_file', 'type']\n",
    "new_columns = cols_to_order + (cast_vote_data.columns.drop(cols_to_order).tolist())\n",
    "cast_vote_data = cast_vote_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the consolidated DataFrame\n",
    "print(cast_vote_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "def match_file_to_metadata(filename, metadata, confirmed_matches, top_n=5):\n",
    "    # Split the filename at the underscores and take the first two elements\n",
    "    key_to_match = '_'.join(filename.split('_')[:2])\n",
    "\n",
    "    # Check if this filename has already been confirmed\n",
    "    if key_to_match in confirmed_matches:\n",
    "        #print(f'Match for {filename} already found in confirmed matches.')\n",
    "        return confirmed_matches[key_to_match]\n",
    "\n",
    "    # Replace NaN values in 'RaceID' with an empty string\n",
    "    metadata['RaceID'].fillna('', inplace=True)\n",
    "\n",
    "    # Try exact matching first\n",
    "    exact_match = metadata[metadata['RaceID'].str.startswith(key_to_match)]\n",
    "\n",
    "    if not exact_match.empty:\n",
    "        print(f'Exact match found for {filename}.')\n",
    "        if len(exact_match) > 1:\n",
    "            print(f'Multiple exact matches found for {filename}, applying fuzzy matching.')\n",
    "            # If there are multiple exact matches, use fuzzy matching on these\n",
    "            top_matches = process.extract(filename, exact_match['RaceID'], scorer=fuzz.token_sort_ratio, limit=top_n)\n",
    "\n",
    "            for match in top_matches:\n",
    "                print(f'Fuzzy match found for {filename} with score {match[1]}')\n",
    "                confirmed_matches[key_to_match] = exact_match[exact_match['RaceID'] == match[0]].iloc[0]\n",
    "        else:\n",
    "            # If there's only one exact match, select it\n",
    "            print(f'Single exact match found for {filename}')\n",
    "            confirmed_matches[key_to_match] = exact_match.iloc[0]\n",
    "    else:\n",
    "        # If no exact match, use fuzzy matching\n",
    "        print(f'No exact match found for {filename}, applying fuzzy matching.')\n",
    "        top_matches = process.extract(key_to_match, metadata['RaceID'], scorer=fuzz.token_sort_ratio, limit=top_n)\n",
    "\n",
    "        # Just pick the top match without user confirmation\n",
    "        print(f'Top fuzzy match selected for {filename} with score {top_matches[0][1]}')\n",
    "        confirmed_matches[key_to_match] = metadata[metadata['RaceID'] == top_matches[0][0]].iloc[0]\n",
    "\n",
    "    # Save confirmed matches to CSV\n",
    "    confirmed_matches_df = pd.DataFrame(list(confirmed_matches.items()), columns=['source_file', 'matched_metadata'])\n",
    "    confirmed_matches_df.to_csv(f'{main_dir_path}/MatchedMetadata.csv', index=False)\n",
    "\n",
    "    print(f'Match for {filename} saved to CSV.')\n",
    "    return confirmed_matches[key_to_match]\n",
    "\n",
    "# Separate metadata frames by type\n",
    "metadata_single = pd.read_csv(\"rcv_elections_database/SingleWinnerRCV.csv\")\n",
    "metadata_sequential = pd.read_csv(\"rcv_elections_database/SequentialRCV.csv\")\n",
    "metadata_proportional = pd.read_csv(\"rcv_elections_database/ProportionalRCV.csv\")\n",
    "\n",
    "# Create a dictionary to store confirmed matches\n",
    "confirmed_matches = {}\n",
    "\n",
    "# If a match is found, we add the state and location to the data frame.\n",
    "for index, row in cast_vote_data.iterrows():\n",
    "    # We use the type column to select the corresponding metadata rows\n",
    "    if row['type'] == \"single\":\n",
    "        metadata_type = metadata_single\n",
    "    elif row['type'] == \"sequential\":\n",
    "        metadata_type = metadata_sequential\n",
    "    elif row['type'] == \"proportional\":\n",
    "        metadata_type = metadata_proportional\n",
    "    else:\n",
    "        continue  # Skip if type is not recognized\n",
    "\n",
    "    matched_metadata = match_file_to_metadata(row['source_file'], metadata_type, confirmed_matches)\n",
    "\n",
    "    if matched_metadata is not None:\n",
    "        cast_vote_data.loc[index, 'State'] = matched_metadata['State']\n",
    "        cast_vote_data.loc[index, 'Location'] = matched_metadata['Jurisdiction']\n",
    "        cast_vote_data.loc[index, 'Year'] = matched_metadata['Year']\n",
    "\n",
    "# Reordering the columns\n",
    "cols_to_order = ['source_file', 'type', 'State', 'Location', 'Year']\n",
    "new_columns = cols_to_order + (cast_vote_data.columns.drop(cols_to_order).tolist())\n",
    "cast_vote_data = cast_vote_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the consolidated DataFrame\n",
    "print(cast_vote_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the matched metadata\n",
    "confirmed_matches_csv= f'{main_dir_path}/MatchedMetadata.csv'\n",
    "confirmed_matches_df = pd.read_csv(confirmed_matches_csv)\n",
    "print(confirmed_matches_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def use_saved_matches(filename, confirmed_matches_csv=f'{main_dir_path}/MatchedMetadata.csv'):\n",
    "    # Load the confirmed matches from the CSV file\n",
    "    confirmed_matches_df = pd.read_csv(confirmed_matches_csv)\n",
    "    confirmed_matches = confirmed_matches_df.set_index('source_file')['matched_metadata'].to_dict()\n",
    "\n",
    "    # Check if this filename has a confirmed match\n",
    "    key_to_match = '_'.join(filename.split('_')[:2])\n",
    "    return confirmed_matches.get(key_to_match, None)\n",
    "\n",
    "def consolidate_data_using_saved_matches(cast_vote_data, confirmed_matches_csv=f'{main_dir_path}/MatchedMetadata.csv'):\n",
    "    # Load the confirmed matches from the CSV file\n",
    "    confirmed_matches_df = pd.read_csv(confirmed_matches_csv)\n",
    "    confirmed_matches = confirmed_matches_df.set_index('source_file')['matched_metadata'].to_dict()\n",
    "\n",
    "    # If a match is found, we add the state and location to the data frame.\n",
    "    for index, row in cast_vote_data.iterrows():\n",
    "        key_to_match = '_'.join(row['source_file'].split('_')[:2])\n",
    "        \n",
    "        matched_metadata = confirmed_matches.get(key_to_match, None)\n",
    "\n",
    "        if matched_metadata is not None:\n",
    "            cast_vote_data.loc[index, 'State'] = matched_metadata['State']\n",
    "            cast_vote_data.loc[index, 'Location'] = matched_metadata['Jurisdiction']\n",
    "            cast_vote_data.loc[index, 'Year'] = matched_metadata['Year']\n",
    "\n",
    "    # Reordering the columns\n",
    "    cols_to_order = ['source_file', 'type', 'State', 'Location', 'Year']\n",
    "    new_columns = cols_to_order + (cast_vote_data.columns.drop(cols_to_order).tolist())\n",
    "    cast_vote_data = cast_vote_data[new_columns]\n",
    "\n",
    "    return cast_vote_data\n",
    "\n",
    "cast_vote_data = consolidate_data_using_saved_matches(cast_vote_data, confirmed_matches_csv=f'{main_dir_path}/MatchedMetadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the consolidated DataFrame\n",
    "print(cast_vote_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'Burlington_03072023_CityCouncilCentralDistrict.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for MDS\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform MDS\n",
    "mds = MDS(n_components=2, metric=False, dissimilarity='euclidean')\n",
    "mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(mds_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the MDS coordinates and color code them by cluster label\n",
    "plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'MDS plot for election Burlington_03072023_CityCouncilCentralDistrict.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'Burlington_03072023_CityCouncilCentralDistrict.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(pca_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the PCA coordinates and color code them by cluster label\n",
    "plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'PCA plot for election Burlington_03072023_CityCouncilCentralDistrict.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Number of elections to sample\n",
    "n_samples = 50\n",
    "\n",
    "# Randomly sample a subset of the elections\n",
    "elections_sample = np.random.choice(cast_vote_data['source_file'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "# Iterate over the sampled elections\n",
    "for election in elections_sample:\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for MDS\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform MDS\n",
    "    mds = MDS(n_components=2)\n",
    "    mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append(inter_centroid_distance)\n",
    "\n",
    "    # Plot the MDS coordinates and color code them by cluster label\n",
    "    plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "    plt.title(f'MDS plot for election {election}')\n",
    "    plt.show()\n",
    "\n",
    "# List of inter-centroid distances for the sampled elections, convert it to a pandas Series for easier manipulation\n",
    "inter_centroid_distances = pd.Series(inter_centroid_distances, index=elections_sample)\n",
    "\n",
    "# Reindex the inter_centroid_distances Series to match the order of the ballots_per_election Series\n",
    "inter_centroid_distances = inter_centroid_distances.reindex(ballots_per_election.index)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "inter_centroid_distances.plot(kind='barh', figsize=(10, 15))\n",
    "plt.xlabel('Inter-centroid distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid distances for each election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Iterate over all elections\n",
    "for election in cast_vote_data['source_file'].unique():\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for PCA\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append((election, inter_centroid_distance))\n",
    "\n",
    "# Create a DataFrame with inter-centroid distances for all elections\n",
    "inter_centroid_df = pd.DataFrame(inter_centroid_distances, columns=['Election', 'Inter-centroid Distance'])\n",
    "inter_centroid_df.set_index('Election', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by inter-centroid distance in descending order\n",
    "sorted_inter_centroid_df = inter_centroid_df.sort_values(by='Inter-centroid Distance', ascending=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(sorted_inter_centroid_df)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "sorted_inter_centroid_df.plot(kind='barh', figsize=(10, 15), legend=False)\n",
    "plt.xlabel('Inter-centroid Distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid Distances for Each Election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each row in the sorted DataFrame one by one\n",
    "for idx, row in sorted_inter_centroid_df.iterrows():\n",
    "    print(f\"Election: {idx}, Inter-centroid Distance: {row['Inter-centroid Distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'TakomaPark_11082022_Mayor.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(pca_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the PCA coordinates and color code them by cluster label\n",
    "plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'PCA plot for election TakomaPark_11082022_Mayor.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'TakomaPark_11082022_Mayor.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform MDS\n",
    "mds = MDS(n_components=2)\n",
    "mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(mds_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the MDS coordinates and color code them by cluster label\n",
    "plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'MDS plot for election TakomaPark_11082022_Mayor.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of ballots cast for each election\n",
    "ballots_per_election = cast_vote_data['source_file'].value_counts().sort_values()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 15))\n",
    "ballots_per_election.plot(kind='barh')\n",
    "plt.xlabel('Number of ballots cast')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Number of ballots cast in each election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Number of elections to sample\n",
    "n_samples = 50\n",
    "\n",
    "# Randomly sample a subset of the elections\n",
    "elections_sample = np.random.choice(cast_vote_data['source_file'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "# Iterate over the sampled elections\n",
    "for election in elections_sample:\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for PCA\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append(inter_centroid_distance)\n",
    "\n",
    "    # Plot the PCA coordinates and color code them by cluster label\n",
    "    plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "    plt.title(f'PCA plot for election {election}')\n",
    "    plt.show()\n",
    "\n",
    "# List of inter-centroid distances for the sampled elections, convert it to a pandas Series for easier manipulation\n",
    "inter_centroid_distances = pd.Series(inter_centroid_distances, index=elections_sample)\n",
    "\n",
    "# Reindex the inter_centroid_distances Series to match the order of the ballots_per_election Series\n",
    "inter_centroid_distances = inter_centroid_distances.reindex(ballots_per_election.index)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "inter_centroid_distances.plot(kind='barh', figsize=(10, 15))\n",
    "plt.xlabel('Inter-centroid distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid distances for each election')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
