{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCV Elections Database\n",
    "    Proportional ranked choice voting CVRs\n",
    "        .csv\n",
    "    Sequential ranked choice voting CVRs\n",
    "        .csv\n",
    "    Single winner ranked choice voting CVRs\n",
    "        .csv\n",
    ".csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n",
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_97201/3510087131.py:25: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(subdir_path, filename))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the main directory\n",
    "main_dir_path = \"rcv_elections_database/\"\n",
    "\n",
    "# Define the subdirectories\n",
    "subdirectories = [\n",
    "    \"proportional\",\n",
    "    \"sequential\",\n",
    "    \"single\"\n",
    "]\n",
    "\n",
    "# Create a list to store all dataframes\n",
    "dfs = []\n",
    "\n",
    "# Loop over all subdirectories\n",
    "for subdir in subdirectories:\n",
    "    subdir_path = os.path.join(main_dir_path, subdir)\n",
    "\n",
    "    # Loop over all the CSV files in the subdirectory\n",
    "    for filename in os.listdir(subdir_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(os.path.join(subdir_path, filename))\n",
    "            \n",
    "            # Add new columns 'source_file' and 'type' containing the name of the source CSV file and the type of the election, respectively\n",
    "            df['source_file'] = filename\n",
    "            df['type'] = subdir  # This will indicate the type of the election\n",
    "\n",
    "            # Keep only columns that start with 'rank' or are 'source_file' or 'type'\n",
    "            df = df[[col for col in df.columns if col.startswith('rank') or col in ['source_file', 'type']]]\n",
    "\n",
    "            # Append the DataFrame to the list of dataframes\n",
    "            dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list into a single DataFrame\n",
    "cast_vote_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorder the columns to move the rank columns to the end\n",
    "cols_to_order = ['source_file', 'type']\n",
    "new_columns = cols_to_order + (cast_vote_data.columns.drop(cols_to_order).tolist())\n",
    "cast_vote_data = cast_vote_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         source_file          type  \\\n",
      "0  Minneapolis_11072017_BoardofEstimateandTaxatio...  proportional   \n",
      "1  Minneapolis_11072017_BoardofEstimateandTaxatio...  proportional   \n",
      "2  Minneapolis_11072017_BoardofEstimateandTaxatio...  proportional   \n",
      "3  Minneapolis_11072017_BoardofEstimateandTaxatio...  proportional   \n",
      "4  Minneapolis_11072017_BoardofEstimateandTaxatio...  proportional   \n",
      "\n",
      "              rank1             rank2    rank3 rank4 rank5 rank6 rank7 rank8  \\\n",
      "0      Carol Becker  David B. Wheeler  skipped   NaN   NaN   NaN   NaN   NaN   \n",
      "1      Carol Becker  David B. Wheeler  skipped   NaN   NaN   NaN   NaN   NaN   \n",
      "2  David B. Wheeler           skipped  skipped   NaN   NaN   NaN   NaN   NaN   \n",
      "3      Carol Becker           skipped  skipped   NaN   NaN   NaN   NaN   NaN   \n",
      "4           skipped           skipped  skipped   NaN   NaN   NaN   NaN   NaN   \n",
      "\n",
      "   ... rank17 rank18 rank19 rank20 rank21 rank22 rank23 rank24 rank25 rank26  \n",
      "0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "1  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "2  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "3  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "4  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few rows of the consolidated DataFrame\n",
    "print(cast_vote_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: Minneapolis_11072017_BoardofEstimateandTaxation.csv\n",
      "Match in metadata: Minneapolis_11072017_BoardofEstimateandTaxation_tab1 with score 91\n",
      "File name: Cambridge_11082011_CityCouncil.csv\n",
      "Match in metadata: Cambridge_11082011_CityCouncil_tab1 with score 87\n",
      "File name: Minneapolis_11022021_BoardofEstimateandTaxationAtLarge.csv\n",
      "Match in metadata: Minneapolis_11022021_BoardofEstimateandTaxationAtLarge with score 96\n",
      "File name: Cambridge_11152019_CityCouncil.csv\n",
      "Match in metadata: Cambridge_11152019_CityCouncil_tab1 with score 87\n",
      "File name: Minneapolis_11062009_BoardofEstimateandTaxation.csv\n",
      "Match in metadata: Minneapolis_11062009_BoardofEstimateandTaxation_tab1 with score 91\n",
      "File name: Cambridge_11072017_CityCouncil.csv\n",
      "Match in metadata: Cambridge_11072017_CityCouncil_tab1 with score 87\n",
      "File name: Cambridge_11062007_SchoolCommittee.csv\n",
      "Match in metadata: Cambridge_11062007_SchoolCommittee_tab1 with score 88\n",
      "File name: Cambridge_11052013_SchoolCommittee.csv\n",
      "Match in metadata: Cambridge_11052013_SchoolCommittee_tab1 with score 88\n",
      "File name: Cambridge_11032015_SchoolCommittee.csv\n",
      "Match in metadata: Cambridge_11032015_SchoolCommittee_tab1 with score 88\n",
      "File name: Minneapolis_11052013_ParkRecBoardAtLarge.csv\n",
      "Match in metadata: Minneapolis_11052013_ParkRecBoardAtLarge_tab1 with score 90\n",
      "File name: Cambridge_11042003_SchoolCommittee.csv\n",
      "Match in metadata: Cambridge_11042003_SchoolCommittee_tab1 with score 88\n",
      "File name: Cambridge_11082005_CityCouncil.csv\n",
      "Match in metadata: Cambridge_11082005_CityCouncil_tab1 with score 87\n",
      "File name: Minneapolis 2013-board of estimation and taxation cvr.csv\n",
      "Match in metadata: Minneapolis_11052013_BoardofEstimateandTaxation_tab1 with score 48\n",
      "File name: Vineyard_11052019_CityCouncil_tab2.csv\n",
      "Match in metadata: Vineyard_11052019_CityCouncil_tab2 with score 94\n",
      "File name: Payson_11052019_CityCouncil_tab1.csv\n",
      "Match in metadata: Payson_11052019_CityCouncil_tab1 with score 94\n",
      "File name: WoodlandHills_11022021_CityCouncil.csv\n",
      "Match in metadata: WoodlandHills_11022021_CityCouncil with score 94\n",
      "File name: Springville_11022021_CityCouncil4yr.csv\n",
      "Match in metadata: Springville_11022021_CityCouncil4yr with score 95\n",
      "File name: Vineyard_11022021_CityCouncil.csv\n",
      "Match in metadata: Vineyard_11022021_CityCouncil with score 94\n",
      "File name: Genola_11022021_CityCouncil.csv\n",
      "Match in metadata: Genola_11022021_CityCouncil with score 93\n",
      "File name: Portland_06142022_Schoolboarddistrict5.csv\n",
      "Match in metadata: Portland_06142022_SchoolBoardAtLarge_tab1 with score 77\n",
      "File name: Moab_11022021_CityCouncil.csv\n",
      "Match in metadata: Moab_11022021_CityCouncil with score 93\n",
      "File name: Lehi_11022021_CityCouncil.csv\n",
      "Match in metadata: Lehi_11022021_CityCouncil with score 93\n",
      "File name: SanFrancisco_11022010_BoardofSupervisorsDistrict6.csv\n",
      "Match in metadata: SanFrancisco_11022010_BoardofSupervisorsDistrict4 with score 94\n",
      "File name: Oakland_11042014_SchoolDirectorDistrict2.csv\n",
      "Match in metadata: Oakland_11042014_SchoolDirectorDistrict2_tab1 with score 90\n",
      "File name: Albany_11082022_CityCouncil.csv\n",
      "Match in metadata: Oakland_11082022_Mayor with score 70\n",
      "File name: Berkeley_11032020_MemberCityCouncilDist2BerkeleyRCV.csv\n",
      "Match in metadata: Berkeley_11032020_MemberCityCouncilDist2BerkeleyRCV_tab1 with score 92\n",
      "File name: Berkeley_11042014_CityAuditor.csv\n",
      "Match in metadata: Berkeley_11042014_CityAuditor_tab1 with score 87\n",
      "File name: Alaska_11082022_HouseDistrict23.csv\n",
      "Match in metadata: Alaska_11082022_HouseDistrict23 with score 94\n",
      "File name: Oakland_11082016_CouncilAtLrg.csv\n",
      "Match in metadata: Oakland_11082016_CouncilAtLrg_tab1 with score 87\n",
      "File name: SanFrancisco_11082016_BoardofSupervisorsDistrict7.csv\n",
      "Match in metadata: SanFrancisco_11082016_BoardofSupervisorsDistrict7_tab1 with score 92\n",
      "File name: Berkeley_11062018_CityCouncilDistrict1.csv\n",
      "Match in metadata: Berkeley_11062018_CityCouncilDistrict1_tab1 with score 89\n",
      "File name: NewYorkCity_06222021_REPCouncilMember23rdCouncilDistrict.csv\n",
      "Match in metadata: NewYorkCity_06222021_REPCouncilMember23rdCouncilDistrict with score 97\n",
      "File name: Hawaii_05232020_PresidentoftheUnitedStateCD1.csv\n",
      "Match in metadata: Maine_11032020_USSenate with score 47\n",
      "File name: SanFrancisco_06052018_Mayor.csv\n",
      "Match in metadata: SanFrancisco_06052018_Mayor_tab1 with score 86\n",
      "File name: LasCruces_11052019_COUNCILORPOSITION2CITYOFLASCRUCESDISTRICT2COUNCILOR.csv\n",
      "Match in metadata: LasCruces_11052019_COUNCILORPOSITION2CITYOFLASCRUCESDISTRICT2COUNCILOR_tab1 with score 94\n",
      "File name: Maine_07142020_DemocraticCandidateforMaineStateHouseDistrict90.csv\n",
      "Match in metadata: Maine_07142020_DemocraticCandidateforMaineStateHouseDistrict38 with score 94\n",
      "File name: SanFrancisco_11032020_BOARDOFSUPERVISORSDISTRICT9.csv\n",
      "Match in metadata: SanFrancisco_11032020_BOARDOFSUPERVISORSDISTRICT9_tab1 with score 92\n",
      "File name: Oakland_11062012_CityAttorney.csv\n",
      "Match in metadata: Oakland_11062012_CityAttorney_tab1 with score 87\n",
      "File name: Berkeley_11082016_Mayor.csv\n",
      "Match in metadata: Berkeley_11082016_Mayor_tab1 with score 84\n",
      "File name: SantaFe_03062018_Mayor.csv\n",
      "Match in metadata: SantaFe_03062018_Mayor_tab1 with score 83\n",
      "File name: SanLeandro_11062018_Mayor.csv\n",
      "Match in metadata: SanLeandro_11062018_Mayor_tab1 with score 85\n",
      "File name: Corvallis_11082022_CityCouncilWard9.csv\n",
      "Match in metadata: Corvallis_11082022_CityCouncilWard9 with score 95\n",
      "File name: Oakland_11022010_SchoolDirectorDistrict6.csv\n",
      "Match in metadata: Oakland_11022010_SchoolDirectorDistrict6_tab1 with score 90\n",
      "File name: Kansas_05022020_PRESIDENTOFTHEUNITEDSTATES.csv\n",
      "Match in metadata: Basalt_04072020_Mayor with score 56\n",
      "File name: Burlington_03072023_CityCouncilEastDistrict.csv\n",
      "Match in metadata: Burlington_03072023_CityCouncilEastDistrict with score 96\n",
      "File name: SanFrancisco_11062018_BoardofSupervisorsDistrict10.csv\n",
      "Match in metadata: SanFrancisco_11062018_BoardofSupervisorsDistrict10_tab1 with score 92\n",
      "File name: SanFrancisco_11082005_AssessorRecorder.csv\n",
      "Match in metadata: SanFrancisco_11082005_AssessorRecorder_tab1 with score 89\n",
      "File name: Oakland_11082022_CityAuditor.csv\n",
      "Match in metadata: Oakland_11082022_CityAuditor with score 93\n",
      "File name: SanFrancisco_11052019_CityAttorney.csv\n",
      "Match in metadata: SanFrancisco_11052019_CityAttorney_tab1 with score 88\n",
      "File name: Maine_06122018_DemocraticPrimaryforCD2.csv\n",
      "Match in metadata: Maine_06122018_DemocraticPrimaryforCD2_tab1 with score 89\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 103\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m matched_metadata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m         cast_vote_data\u001b[39m.\u001b[39mloc[index, \u001b[39m'\u001b[39m\u001b[39mState\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m matched_metadata[\u001b[39m'\u001b[39m\u001b[39mState\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m         cast_vote_data\u001b[39m.\u001b[39mloc[index, \u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m matched_metadata[\u001b[39m'\u001b[39;49m\u001b[39mJurisdiction\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m    105\u001b[0m \u001b[39m# Reordering the columns\u001b[39;00m\n\u001b[1;32m    106\u001b[0m cols_to_order \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39msource_file\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mState\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:1119\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m-> 1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values[loc]\n\u001b[1;32m   1121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   1122\u001b[0m     mi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/series.py:750\u001b[0m, in \u001b[0;36mSeries._values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_values\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[39m    Return the internal repr of this data (defined by Block.interval_values).\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[39m    This are the values as stored in the Block (ndarray or ExtensionArray\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    748\u001b[0m \n\u001b[1;32m    749\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49minternal_values()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:2013\u001b[0m, in \u001b[0;36mSingleBlockManager.internal_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minternal_values\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2012\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"The array that Series._values returns\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2013\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_block\u001b[39m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import beepy\n",
    "import pandas as pd\n",
    "\n",
    "from threading import Thread, Event\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "def beep_continuously(stop_event):\n",
    "    while not stop_event.is_set():\n",
    "        beepy.beep(sound=1)\n",
    "        time.sleep(2)\n",
    "\n",
    "# Create the stop event\n",
    "#stop_event = Event()\n",
    "\n",
    "# Spawn a thread that runs beep_continuously\n",
    "#beep_thread = Thread(target=beep_continuously, args=(stop_event,))\n",
    "#beep_thread.start()\n",
    "\n",
    "def match_file_to_metadata(filename, metadata, confirmed_matches, top_n=5):\n",
    "    \n",
    "    # Split the filename at the underscores and take the first two elements\n",
    "    key_to_match = '_'.join(filename.split('_')[:2])\n",
    "\n",
    "    # Check if this filename has already been confirmed\n",
    "    if key_to_match in confirmed_matches:\n",
    "        return confirmed_matches[key_to_match]\n",
    "    \n",
    "    # Replace NaN values in 'RaceID' with an empty string\n",
    "    metadata['RaceID'].fillna('', inplace=True)\n",
    "\n",
    "    # Try exact matching first\n",
    "    exact_match = metadata[metadata['RaceID'].str.startswith(key_to_match)]\n",
    "\n",
    "    if not exact_match.empty:\n",
    "        if len(exact_match) > 1:\n",
    "            # If there are multiple exact matches, use fuzzy matching on these\n",
    "            top_matches = process.extract(filename, exact_match['RaceID'], scorer=fuzz.token_sort_ratio, limit=top_n)\n",
    "\n",
    "            for match in top_matches:\n",
    "                # Ask for manual confirmation for each fuzzy match\n",
    "                print(f\"File name: {filename}\")\n",
    "                print(f\"Match in metadata: {match[0]} with score {match[1]}\")\n",
    "                confirmation = \"y\" #input(\"Confirm match? (Y/N): \")\n",
    "                if confirmation.lower() == \"y\":\n",
    "                    confirmed_matches[key_to_match] = exact_match[exact_match['RaceID'] == match[0]].iloc[0]\n",
    "                    return confirmed_matches[key_to_match]\n",
    "        else:\n",
    "            # If there's only one exact match, select it\n",
    "            confirmed_matches[key_to_match] = exact_match.iloc[0]\n",
    "            return confirmed_matches[key_to_match]\n",
    "    \n",
    "    # If no exact match, use fuzzy matching\n",
    "    top_matches = process.extract(key_to_match, metadata['RaceID'], scorer=fuzz.token_sort_ratio, limit=top_n)\n",
    "\n",
    "    for match in top_matches:\n",
    "        # If the match score is above 80 but less than 100, ask for manual confirmation\n",
    "        if match[1] > 10:\n",
    "            print(f\"File name: {filename}\")\n",
    "            print(f\"Match in metadata: {match[0]} with score {match[1]}\")\n",
    "\n",
    "            # Clear stop event to start beeping\n",
    "            #stop_event.clear()\n",
    "\n",
    "            confirmation = \"y\" #input(\"Confirm match? (Y/N): \")\n",
    "\n",
    "            # Set stop event to stop beeping\n",
    "            #stop_event.set()\n",
    "\n",
    "            if confirmation.lower() == \"y\":\n",
    "                confirmed_matches[key_to_match] = metadata[metadata['RaceID'] == match[0]].iloc[0]\n",
    "                return confirmed_matches[key_to_match]\n",
    "            \n",
    "    print(f\"No match found for file: {filename}\")\n",
    "    confirmed_matches[key_to_match] = None  # Store the fact that no match was found\n",
    "\n",
    "    return None\n",
    "\n",
    "# Separate metadata frames by type\n",
    "metadata_single = pd.read_csv(\"rcv_elections_database/SingleWinnerRCV.csv\")\n",
    "metadata_sequential = pd.read_csv(\"rcv_elections_database/SequentialRCV.csv\")\n",
    "metadata_proportional = pd.read_csv(\"rcv_elections_database/ProportionalRCV.csv\")\n",
    "\n",
    "# Create a dictionary to store confirmed matches\n",
    "confirmed_matches = {}\n",
    "\n",
    "# If a match is found, we add the state and location to the data frame.\n",
    "for index, row in cast_vote_data.iterrows():\n",
    "    # We use the type column to select the corresponding metadata rows\n",
    "    if row['type'] == \"single\":\n",
    "        metadata_type = metadata_single\n",
    "    elif row['type'] == \"sequential\":\n",
    "        metadata_type = metadata_sequential\n",
    "    elif row['type'] == \"proportional\":\n",
    "        metadata_type = metadata_proportional\n",
    "    else:\n",
    "        continue  # Skip if type is not recognized\n",
    "\n",
    "    matched_metadata = match_file_to_metadata(row['source_file'], metadata_type, confirmed_matches)\n",
    "\n",
    "    if matched_metadata is not None:\n",
    "        cast_vote_data.loc[index, 'State'] = matched_metadata['State']\n",
    "        cast_vote_data.loc[index, 'Location'] = matched_metadata['Jurisdiction']\n",
    "\n",
    "# Reordering the columns\n",
    "cols_to_order = ['source_file', 'type', 'State', 'Location']\n",
    "new_columns = cols_to_order + (cast_vote_data.columns.drop(cols_to_order).tolist())\n",
    "cast_vote_data = cast_vote_data[new_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of ballots cast for each election\n",
    "ballots_per_election = cast_vote_data['source_file'].value_counts().sort_values()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 15))\n",
    "ballots_per_election.plot(kind='barh')\n",
    "plt.xlabel('Number of ballots cast')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Number of ballots cast in each election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Census API key\n",
    "api_key = '662ad2b75e57af64cf96d3e2af7c49e1d324bb7c'\n",
    "\n",
    "# Define the base URL for the decennial census API, P4_001N is the total population over 18 years old\n",
    "base_url = f'https://api.census.gov/data/2020/dec/pl?get=NAME,P3_001N&for=state:*&key={api_key}'\n",
    "\n",
    "# Send a GET request to the API\n",
    "response = requests.get(base_url)\n",
    "\n",
    "# Print out the response text\n",
    "print(response.text)\n",
    "\n",
    "# Load the response as a JSON object\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Convert the JSON object to a DataFrame\n",
    "census_data = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(census_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'Burlington_03072023_CityCouncilCentralDistrict.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for MDS\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform MDS\n",
    "mds = MDS(n_components=2, metric=False, dissimilarity='euclidean')\n",
    "mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(mds_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the MDS coordinates and color code them by cluster label\n",
    "plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'MDS plot for election Burlington_03072023_CityCouncilCentralDistrict.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'Burlington_03072023_CityCouncilCentralDistrict.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(pca_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the PCA coordinates and color code them by cluster label\n",
    "plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'PCA plot for election Burlington_03072023_CityCouncilCentralDistrict.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Number of elections to sample\n",
    "n_samples = 50\n",
    "\n",
    "# Randomly sample a subset of the elections\n",
    "elections_sample = np.random.choice(cast_vote_data['source_file'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "# Iterate over the sampled elections\n",
    "for election in elections_sample:\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for MDS\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform MDS\n",
    "    mds = MDS(n_components=2)\n",
    "    mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append(inter_centroid_distance)\n",
    "\n",
    "    # Plot the MDS coordinates and color code them by cluster label\n",
    "    plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "    plt.title(f'MDS plot for election {election}')\n",
    "    plt.show()\n",
    "\n",
    "# List of inter-centroid distances for the sampled elections, convert it to a pandas Series for easier manipulation\n",
    "inter_centroid_distances = pd.Series(inter_centroid_distances, index=elections_sample)\n",
    "\n",
    "# Reindex the inter_centroid_distances Series to match the order of the ballots_per_election Series\n",
    "inter_centroid_distances = inter_centroid_distances.reindex(ballots_per_election.index)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "inter_centroid_distances.plot(kind='barh', figsize=(10, 15))\n",
    "plt.xlabel('Inter-centroid distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid distances for each election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Iterate over all elections\n",
    "for election in cast_vote_data['source_file'].unique():\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for PCA\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append((election, inter_centroid_distance))\n",
    "\n",
    "# Create a DataFrame with inter-centroid distances for all elections\n",
    "inter_centroid_df = pd.DataFrame(inter_centroid_distances, columns=['Election', 'Inter-centroid Distance'])\n",
    "inter_centroid_df.set_index('Election', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by inter-centroid distance in descending order\n",
    "sorted_inter_centroid_df = inter_centroid_df.sort_values(by='Inter-centroid Distance', ascending=False)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(sorted_inter_centroid_df)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "sorted_inter_centroid_df.plot(kind='barh', figsize=(10, 15), legend=False)\n",
    "plt.xlabel('Inter-centroid Distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid Distances for Each Election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each row in the sorted DataFrame one by one\n",
    "for idx, row in sorted_inter_centroid_df.iterrows():\n",
    "    print(f\"Election: {idx}, Inter-centroid Distance: {row['Inter-centroid Distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'TakomaPark_11082022_Mayor.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(pca_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the PCA coordinates and color code them by cluster label\n",
    "plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'PCA plot for election TakomaPark_11082022_Mayor.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Filter DataFrame to include only the current election\n",
    "election_df = cast_vote_data[cast_vote_data['source_file'] == 'TakomaPark_11082022_Mayor.csv'].copy()\n",
    "\n",
    "# Convert candidate names to numeric IDs for PCA\n",
    "le = LabelEncoder()\n",
    "for col in election_df.columns:\n",
    "    if col.startswith('rank'):\n",
    "        # Handle missing values by replacing them with a placeholder\n",
    "        election_df[col] = election_df[col].fillna('Missing')\n",
    "        election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "# Perform MDS\n",
    "mds = MDS(n_components=2)\n",
    "mds_coordinates = mds.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "# Perform KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "kmeans.fit(mds_coordinates)\n",
    "\n",
    "# Compute the inter-centroid distance\n",
    "centroid1, centroid2 = kmeans.cluster_centers_\n",
    "inter_centroid_distance = euclidean(centroid1, centroid2)\n",
    "\n",
    "# Plot the MDS coordinates and color code them by cluster label\n",
    "plt.scatter(mds_coordinates[:, 0], mds_coordinates[:, 1], c=kmeans.labels_)\n",
    "plt.title(f'MDS plot for election TakomaPark_11082022_Mayor.csv')\n",
    "plt.show()\n",
    "\n",
    "print('Inter-centroid distance:', inter_centroid_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "inter_centroid_distances = []\n",
    "\n",
    "# Number of elections to sample\n",
    "n_samples = 50\n",
    "\n",
    "# Randomly sample a subset of the elections\n",
    "elections_sample = np.random.choice(cast_vote_data['source_file'].unique(), size=n_samples, replace=False)\n",
    "\n",
    "# Iterate over the sampled elections\n",
    "for election in elections_sample:\n",
    "    # Filter DataFrame to include only the current election\n",
    "    election_df = cast_vote_data[cast_vote_data['source_file'] == election].copy()\n",
    "\n",
    "    # Convert candidate names to numeric IDs for PCA\n",
    "    le = LabelEncoder()\n",
    "    for col in election_df.columns:\n",
    "        if col.startswith('rank'):\n",
    "            # Handle missing values by replacing them with a placeholder\n",
    "            election_df[col] = election_df[col].fillna('Missing')\n",
    "            election_df[col] = le.fit_transform(election_df[col])\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_coordinates = pca.fit_transform(election_df.drop(columns=['source_file', 'type']))\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=2)  # assuming two clusters; adjust as needed\n",
    "    kmeans.fit(pca_coordinates)\n",
    "\n",
    "    # Compute the inter-centroid distance and store it\n",
    "    centroid1, centroid2 = kmeans.cluster_centers_\n",
    "    inter_centroid_distance = distance.euclidean(centroid1, centroid2)\n",
    "    inter_centroid_distances.append(inter_centroid_distance)\n",
    "\n",
    "    # Plot the PCA coordinates and color code them by cluster label\n",
    "    plt.scatter(pca_coordinates[:, 0], pca_coordinates[:, 1], c=kmeans.labels_)\n",
    "    plt.title(f'PCA plot for election {election}')\n",
    "    plt.show()\n",
    "\n",
    "# List of inter-centroid distances for the sampled elections, convert it to a pandas Series for easier manipulation\n",
    "inter_centroid_distances = pd.Series(inter_centroid_distances, index=elections_sample)\n",
    "\n",
    "# Reindex the inter_centroid_distances Series to match the order of the ballots_per_election Series\n",
    "inter_centroid_distances = inter_centroid_distances.reindex(ballots_per_election.index)\n",
    "\n",
    "# Plot the inter-centroid distances\n",
    "inter_centroid_distances.plot(kind='barh', figsize=(10, 15))\n",
    "plt.xlabel('Inter-centroid distance')\n",
    "plt.ylabel('Election')\n",
    "plt.title('Inter-centroid distances for each election')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
