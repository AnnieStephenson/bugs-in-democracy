{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gubenatorial\n",
    "# senate\n",
    "\n",
    "\n",
    "# correlation table on the bimodality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bimodality & gamma and serve the brutons!@#$%^&*()_+ \n",
    "#(new york election, maybe use a plotting method to inspect individual points more easliy [seaborn?])\n",
    "# code \"problem\" elections, maybe sort across and see if there are any patterns\n",
    "# get a rule that culls elections and only plot problem elections\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the sys.path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import kurtosis, skew, gaussian_kde\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "from rcv_learning.rcv_distribution import *\n",
    "from rcv_learning.rcv_dimensionality import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ecdf(data):\n",
    "    \"\"\"Compute the empirical cumulative distribution function (ECDF) of data.\"\"\"\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "    return sorted_data, np.arange(1, n+1) / n\n",
    "\n",
    "def dip_statistic(data):\n",
    "    \"\"\"Compute Hartigan's dip statistic for data.\"\"\"\n",
    "    data = np.sort(data)\n",
    "    n = len(data)\n",
    "    \n",
    "    # Compute the empirical CDF\n",
    "    x, ecdf = compute_ecdf(data)\n",
    "    \n",
    "    # Compute the greatest difference on the left and right side for each data point\n",
    "    U = np.arange(1, n+1) / n\n",
    "    D = U - np.arange(0, n) / n\n",
    "    \n",
    "    # Calculate the difference between the empirical distribution function and the unimodal distribution function that minimizes that maximum difference.\n",
    "    low_dip = (ecdf - D).clip(min=0)\n",
    "    up_dip = (U - ecdf).clip(min=0)\n",
    "    both_dips = np.column_stack((low_dip, up_dip))\n",
    "    \n",
    "    # The dip statistic is the maximum difference over all data points\n",
    "    dip = np.max(both_dips)\n",
    "    \n",
    "    return dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:188: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized distances: {'Tom Steyer': 0.0, 'Pete Buttigieg': 1.6495163108636355, 'Michael R. Bloomberg': 2.8359621738191514, 'Amy Klobuchar': 3.1870559040940774, 'Elizabeth Warren': 3.594452193656948, 'Bernie Sanders': 4.067825929677619, 'Joseph R. Biden': 4.138892437653406, '(undeclared)': 6.057519997888765, 'Tulsi Gabbard': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:188: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency points: {4.260463276280078: 636, 4.024807137358229: 2402, 3.9462550910509457: 3270, 3.682402918005447: 46, 3.980831775183979: 205, 3.76095496431273: 25, 6.057519997888763: 107, 3.1135354031270994: 10, 8.0: 32, 1.6495163108636353: 8, 5.195347457210058: 60, 3.92990723898862: 58, 3.8860205227042544: 75, 3.907963880846437: 2, 4.210219144714901: 3, 3.7216789411590883: 53, 4.082049035490957: 9, 3.631478381810088: 6, 3.9553695070862993: 15, 4.959691318288209: 26, 2.128801107540854: 11, 3.1920874494343825: 6, 3.8338110144117175: 9, 0.9865637727627364: 4, 3.673104074474034: 3, 4.7097274566822485: 56, 2.223701005910463: 21, 2.835962173819151: 13, 3.3768557008332944: 8, 2.2629770290641043: 8, 3.904671927542749: 2, 4.8689790865330025: 4, 2.076630874307236: 1, 2.179725643736213: 7, 4.4740713177604: 58, 3.052121619312311: 1, 3.1846632516794893: 5, 3.8118676562695346: 4, 2.8806638920474357: 1, 2.168077130694496: 3, 2.12645143803055: 1, 3.612324828136743: 5, 4.017974579381618: 4, 3.5944521936569473: 7, 3.8193400629145886: 3, 3.517837978963566: 5, 3.944397828015208: 9, 2.978473712821535: 1, 3.3328803386590447: 7, 3.439285932656283: 5, 3.152811426280741: 6, 3.680039837341663: 2, 3.6770913173667505: 1, 3.0005742345978224: 1, 3.991073846644131: 1, 2.9652296702576604: 2, 3.9859528109140547: 8, 2.0409390290822387: 2, 2.033901209171246: 3, 3.0255846787786: 1, 3.9334261489441165: 8, 3.1870559040940774: 6, 2.0175114670525085: 1, 3.288904976484795: 3, 3.9994031772827983: 2, 3.3774435164818266: 1, 3.548573063770018: 2, 6.1988225757188244: 1, 3.674273314919226: 2, 1.9461277766025142: 2, 3.320035499410033: 1, 3.6001204484845064: 2, 2.1068134264537295: 2, 3.414743209534589: 1, 3.3525183502358655: 1, 3.641351629836554: 1, 3.898607161358477: 1, 3.06956004095285: 1, 2.1357502815619633: 2, 0.8870531812624036: 1, 2.6710894070512063: 1, 0.0: 5, 2.302253052217746: 3, 1.7399382377445598: 1, 2.1727904547924113: 1, 1.4932818863813684: 1, 2.3162241779292816: 1, 2.238767483131093: 1, 3.372156361812686: 1, 4.0601056773487745: 1, 3.9604905428163755: 2, 1.5143799994721907: 1, 3.043781716564943: 1, 0.6398971237007457: 1, 2.751517232619917: 1, 2.672335104089466: 1, 3.304470237947414: 3, 2.2190016668898545: 1, 2.11663243224214: 2, 2.759040131399706: 1, 3.5875916655257223: 4, 0.8356084828100475: 1, 3.0786585598460214: 1, 3.4161317239869358: 4, 4.390291928070559: 1, 2.055266041739241: 2, 2.9237356063878828: 1, 2.3313177119903976: 1, 3.0967125273309897: 1, 2.48760911926519: 2, 2.0848257453666044: 1, 3.3116484401056114: 2, 4.021346535424981: 1, 2.996647823670366: 1, 1.0258397959163779: 4, 3.236784114082142: 1, 1.3983819880117596: 1, 3.8708874476290775: 2, 2.0849143912564885: 1, 3.673055526181406: 1, 2.025706338111877: 1, 3.6661437118330054: 1, 3.0891980525296705: 1, 4.6627895476750485: 1, 2.199363655313034: 1, 2.99540717451813: 1, 4.126971630364363: 1}\n"
     ]
    }
   ],
   "source": [
    "# Test the function with a custom CSV file\n",
    "csv = \"../rcv_elections_database/single/Wyoming_04172020_PRESIDENTOFTHEUNITEDSTATES.csv\"\n",
    "\n",
    "# Determine save behavior\n",
    "save = True\n",
    "filename = csv.split(\"/\")[-1]\n",
    "filename_prefix = f\"plots/{filename}\"\n",
    "\n",
    "# Perform the RCV analysis\n",
    "test = perform_rcv_analysis(csv, n_runs=1000)\n",
    "mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names = test\n",
    "\n",
    "# Print the normalized distances between candidates and plot the MDS analysis\n",
    "normalized_distances = get_distances_normalized(most_common_order, mds_1d_coordinates, candidate_names)\n",
    "print(\"Normalized distances:\", normalized_distances)\n",
    "plot_rcv_analysis(mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names, save=save, filename=filename_prefix)\n",
    "\n",
    "# Get the consistency points for the bimodality analysis\n",
    "points = get_consistency_points(csv)\n",
    "print(\"Consistency points:\", points)\n",
    "\n",
    "# Create a list of data points\n",
    "data_points = []\n",
    "for key, value in points.items():\n",
    "    data_points.extend([key] * value)\n",
    "\n",
    "# Convert to numpy array\n",
    "data_points = np.array(data_points)\n",
    "\n",
    "# Calculate skewness and kurtosis\n",
    "g = skew(data_points)\n",
    "k = kurtosis(data_points)\n",
    "\n",
    "# Calculate KDE without plotting\n",
    "density = gaussian_kde(data_points)\n",
    "x_vals = np.linspace(min(data_points), max(data_points), 1000)\n",
    "y_vals = density(x_vals)\n",
    "\n",
    "# Identify local maxima in the KDE\n",
    "maxima_indices = argrelextrema(y_vals, np.greater)\n",
    "\n",
    "# Get the x-values of the maxima\n",
    "modes = x_vals[maxima_indices]\n",
    "\n",
    "# Check if there are at least two modes\n",
    "if len(modes) >= 2:\n",
    "    mode1, mode2 = modes[:2]\n",
    "\n",
    "    # Calculate the amplitudes of the two modes\n",
    "    amp1 = density(mode1)[0]\n",
    "    amp2 = density(mode2)[0]\n",
    "\n",
    "    # Calculate the amplitude ratio with higher amplitude as denominator\n",
    "    if amp1 > amp2:\n",
    "        amplitude_ratio = amp2 / amp1\n",
    "    else:\n",
    "        amplitude_ratio = amp1 / amp2\n",
    "\n",
    "    # Calculate x-axis distance between the two modes\n",
    "    mode_distance = abs(mode2 - mode1)\n",
    "\n",
    "else:\n",
    "    mode1, mode2 = None, None\n",
    "    amplitude_ratio = None\n",
    "    mode_distance = None\n",
    "\n",
    "try:\n",
    "    # Split the data into two groups based on proximity to the modes\n",
    "    data_group1 = [point for point in data_points if abs(point - mode1) < abs(point - mode2)]\n",
    "    data_group2 = [point for point in data_points if abs(point - mode1) > abs(point - mode2)]\n",
    "\n",
    "    # Display mean and variance for each group\n",
    "    mu1, sigma1_sq = np.mean(data_group1), np.var(data_group1)\n",
    "    mu2, sigma2_sq = np.mean(data_group2), np.var(data_group2)\n",
    "\n",
    "    # Calculate Ashman's D statistic (D > 2)\n",
    "    ashmans_D = abs(mu1 - mu2) / np.sqrt((sigma1_sq + sigma2_sq) / 2)\n",
    "except:\n",
    "    mode_distance = 404\n",
    "    amplitude_ratio = 404\n",
    "    ashmans_D = 404\n",
    "\n",
    "# Calculate Sarle's bimodality coefficient b (b > 5/9)\n",
    "n = len(data_points)\n",
    "sarle = (g**2 + 1) / (k + 3 * (n-1)**2 / ((n-2) * (n-3)))\n",
    "\n",
    "# Calculate Hartigan's dip statistic (calculate p value)\n",
    "hartigan_dip = dip_statistic(data_points)\n",
    "\n",
    "# Prepare data for histogram\n",
    "data_list = [x for x, count in points.items() for _ in range(count)]\n",
    "normalized_points = []\n",
    "normalized_names = []\n",
    "for name in normalized_distances:\n",
    "    normalized_names.append(name)\n",
    "    normalized_points.append(normalized_distances[name])\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data_list, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Histogram of Data')\n",
    "plt.xticks(normalized_points, normalized_names, rotation=45)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display measures in a text box\n",
    "text_str = f\"Skewness: {g:.2f}\\nKurtosis: {k:.2f}\\nMode Distance: {mode_distance:.2f}\"\n",
    "plt.text(0.05, 0.95, text_str, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "if save:\n",
    "    plt.savefig(f\"{filename_prefix}_hist.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()\n",
    "\n",
    "# Plot kernal density estimation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data_list, fill=True)\n",
    "plt.title('Kernel Density Estimation of Data')\n",
    "plt.xticks(normalized_points, normalized_names, rotation=45)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display bimodality measures in a text box\n",
    "text_str = f\"Ashman's D: {ashmans_D:.10f}\\nSarle's Coefficient: {sarle:.10f}\\nHartigan's Dip: {hartigan_dip:.10f}\\nAmplitude Ratio: {amplitude_ratio:.10f}\"\n",
    "plt.text(0.05, 0.95, text_str, transform=plt.gca().transAxes, fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "if save:\n",
    "    plt.savefig(f\"{filename_prefix}_kde.png\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
