{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the sys.path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g2/25z774tn0599smwks8_v_k200000gp/T/ipykernel_87303/4019494009.py:10: DeprecationWarning: Please use `gaussian_kde` from the `scipy.stats` namespace, the `scipy.stats.kde` namespace is deprecated.\n",
      "  from scipy.stats.kde import gaussian_kde\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import kurtosis, skew, rankdata\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "\n",
    "from rcv_learning.rcv_distribution import *\n",
    "from rcv_learning.rcv_dimensionality import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the edge case for sarles against ashmans D\n",
    "\n",
    "# compare likelihoods for the unimodal vs multimodal, bimodal ratio (make pretty historgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ecdf(data):\n",
    "    \"\"\"Compute the empirical cumulative distribution function (ECDF) of data.\"\"\"\n",
    "    sorted_data = np.sort(data)\n",
    "    n = len(data)\n",
    "    return sorted_data, np.arange(1, n+1) / n\n",
    "\n",
    "def dip_statistic(data):\n",
    "    \"\"\"Compute Hartigan's dip statistic for data.\"\"\"\n",
    "    data = np.sort(data)\n",
    "    n = len(data)\n",
    "    \n",
    "    # Compute the empirical CDF\n",
    "    x, ecdf = compute_ecdf(data)\n",
    "    \n",
    "    # Compute the greatest difference on the left and right side for each data point\n",
    "    U = np.arange(1, n+1) / n\n",
    "    D = U - np.arange(0, n) / n\n",
    "    \n",
    "    # Calculate the difference between the empirical distribution function and the \n",
    "    # unimodal distribution function that minimizes that maximum difference.\n",
    "    low_dip = (ecdf - D).clip(min=0)\n",
    "    up_dip = (U - ecdf).clip(min=0)\n",
    "    both_dips = np.column_stack((low_dip, up_dip))\n",
    "    \n",
    "    # The dip statistic is the maximum difference over all data points\n",
    "    dip = np.max(both_dips)\n",
    "    \n",
    "    return dip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../rcv_elections_database/CandidateDetails.csv\n",
      "No matching row found for file: CandidateDetails.csv\n",
      "../rcv_elections_database/SingleWinnerRCV.csv\n",
      "No matching row found for file: SingleWinnerRCV.csv\n",
      "../rcv_elections_database/MatchedElections.csv\n",
      "No matching row found for file: MatchedElections.csv\n",
      "../rcv_elections_database/SequentialRCV.csv\n",
      "No matching row found for file: SequentialRCV.csv\n",
      "../rcv_elections_database/ProportionalRCV.csv\n",
      "No matching row found for file: ProportionalRCV.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11072017_BoardofEstimateandTaxation.csv\n",
      "No matching row found for file: Minneapolis_11072017_BoardofEstimateandTaxation.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11072017_ParkBoardAtLarge.csv\n",
      "No matching row found for file: Minneapolis_11072017_ParkBoardAtLarge.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11082011_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11082011_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11022021_BoardofEstimateandTaxationAtLarge.csv\n",
      "No matching row found for file: Minneapolis_11022021_BoardofEstimateandTaxationAtLarge.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11152019_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11152019_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11062009_BoardofEstimateandTaxation.csv\n",
      "No matching row found for file: Minneapolis_11062009_BoardofEstimateandTaxation.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11072017_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11072017_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11062001_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11062001_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11032009_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11032009_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11062007_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11062007_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11052013_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11052013_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Eastpointe_11022021_CityCouncil.csv\n",
      "No matching row found for file: Eastpointe_11022021_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11062007_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11062007_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11152019_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11152019_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11032015_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11032015_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11082011_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11082011_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11052013_ParkRecBoardAtLarge.csv\n",
      "No matching row found for file: Minneapolis_11052013_ParkRecBoardAtLarge.csv\n",
      "../rcv_elections_database/proportional/Eastpointe_11052019_CityCouncil.csv\n",
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:170: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../rcv_elections_database/proportional/Cambridge_11052013_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11052013_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Minneapolis_11062009_MinneapolisParkRecBoard.csv\n",
      "No matching row found for file: Minneapolis_11062009_MinneapolisParkRecBoard.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11042003_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11042003_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11072017_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11072017_SchoolCommittee.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11032015_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11032015_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11082005_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11082005_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Minneapolis 2013-board of estimation and taxation cvr.csv\n",
      "No matching row found for file: Minneapolis 2013-board of estimation and taxation cvr.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11042003_CityCouncil.csv\n",
      "No matching row found for file: Cambridge_11042003_CityCouncil.csv\n",
      "../rcv_elections_database/proportional/Cambridge_11082005_SchoolCommittee.csv\n",
      "No matching row found for file: Cambridge_11082005_SchoolCommittee.csv\n",
      "../rcv_elections_database/classic/Albany_11082022_CityCouncil.csv\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:170: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../rcv_elections_database/classic/Alaska_08162022_HouseofRepresentativesSpecial.csv\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/es5891/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:170: RuntimeWarning: divide by zero encountered in divide\n",
      "  distance = 1 / np.sqrt(freq_upper_triangle)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(row_index)\n\u001b[1;32m     25\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[39m# Get the consistency points for the election\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     points \u001b[39m=\u001b[39m get_consistency_points(file_path)\n\u001b[1;32m     29\u001b[0m     \u001b[39m# Create a list of data points\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     data_points \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_distribution.py:181\u001b[0m, in \u001b[0;36mget_consistency_points\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_consistency_points\u001b[39m(file: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m]:\n\u001b[1;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39m    Performs RCV analysis and normalizes the distances of MDS-1D coordinates,\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m    then calculates the consistency of each ballot and collects points based on this consistency.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39m        a list of candidates in their most consistent permutation, and a list of mds-1d coordinates.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     rcv_and_normalized_results \u001b[39m=\u001b[39m perform_rcv_and_normalize(file)\n\u001b[1;32m    182\u001b[0m     most_consistent_permutation \u001b[39m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m     permutation_numbers \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:279\u001b[0m, in \u001b[0;36mperform_rcv_and_normalize\u001b[0;34m(csv_file, n_runs)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39mPerform the ranked-choice-voting (RCV) analysis and normalize the distances of MDS-1D coordinates.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39mReturn a dictionary with candidate names as keys and normalized distances as values.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39m    A dictionary mapping candidate names to normalized MDS-1D coordinates.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39m# Perform the RCV analysis\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m mds_1d_coordinates, mds_2d_coordinates, most_common_order, order_frequencies, candidate_names \u001b[39m=\u001b[39m perform_rcv_analysis(csv_file, n_runs)\n\u001b[1;32m    281\u001b[0m \u001b[39m# Normalize the distances\u001b[39;00m\n\u001b[1;32m    282\u001b[0m normalized_coordinates_dict \u001b[39m=\u001b[39m get_distances_normalized(most_common_order, mds_1d_coordinates, candidate_names)\n",
      "File \u001b[0;32m~/Documents/GitHub/bugs-in-democracy/rcv_exploration/../rcv_learning/rcv_dimensionality.py:196\u001b[0m, in \u001b[0;36mperform_rcv_analysis\u001b[0;34m(csv_file, n_runs, random_state, ignore_values, metric)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m# Fit and transform the distance matrix\u001b[39;00m\n\u001b[1;32m    195\u001b[0m values_1d \u001b[39m=\u001b[39m mds_1d\u001b[39m.\u001b[39mfit_transform(distance)\n\u001b[0;32m--> 196\u001b[0m values_2d \u001b[39m=\u001b[39m mds_2d\u001b[39m.\u001b[39;49mfit_transform(distance)\n\u001b[1;32m    198\u001b[0m \u001b[39m# Identify orders in 1D and 2D TODO Procrustes alignment for 2d ordering\u001b[39;00m\n\u001b[1;32m    199\u001b[0m order_1d \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(np\u001b[39m.\u001b[39margsort(values_1d\u001b[39m.\u001b[39mflatten()))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/manifold/_mds.py:613\u001b[0m, in \u001b[0;36mMDS.fit_transform\u001b[0;34m(self, X, y, init)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    611\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdissimilarity_matrix_ \u001b[39m=\u001b[39m euclidean_distances(X)\n\u001b[0;32m--> 613\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstress_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m smacof(\n\u001b[1;32m    614\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdissimilarity_matrix_,\n\u001b[1;32m    615\u001b[0m     metric\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric,\n\u001b[1;32m    616\u001b[0m     n_components\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m    617\u001b[0m     init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    618\u001b[0m     n_init\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_init,\n\u001b[1;32m    619\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    620\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    621\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    622\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    623\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[1;32m    624\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m     normalized_stress\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized_stress,\n\u001b[1;32m    626\u001b[0m )\n\u001b[1;32m    628\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/manifold/_mds.py:328\u001b[0m, in \u001b[0;36msmacof\u001b[0;34m(dissimilarities, metric, n_components, init, n_init, n_jobs, max_iter, verbose, eps, random_state, return_n_iter, normalized_stress)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_init):\n\u001b[0;32m--> 328\u001b[0m         pos, stress, n_iter_ \u001b[39m=\u001b[39m _smacof_single(\n\u001b[1;32m    329\u001b[0m             dissimilarities,\n\u001b[1;32m    330\u001b[0m             metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    331\u001b[0m             n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[1;32m    332\u001b[0m             init\u001b[39m=\u001b[39;49minit,\n\u001b[1;32m    333\u001b[0m             max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[1;32m    334\u001b[0m             verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    335\u001b[0m             eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    336\u001b[0m             random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    337\u001b[0m             normalized_stress\u001b[39m=\u001b[39;49mnormalized_stress,\n\u001b[1;32m    338\u001b[0m         )\n\u001b[1;32m    339\u001b[0m         \u001b[39mif\u001b[39;00m best_stress \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m stress \u001b[39m<\u001b[39m best_stress:\n\u001b[1;32m    340\u001b[0m             best_stress \u001b[39m=\u001b[39m stress\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/manifold/_mds.py:108\u001b[0m, in \u001b[0;36m_smacof_single\u001b[0;34m(dissimilarities, metric, n_components, init, max_iter, verbose, eps, random_state, normalized_stress)\u001b[0m\n\u001b[1;32m    105\u001b[0m dissimilarities \u001b[39m=\u001b[39m check_symmetric(dissimilarities, raise_exception\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    107\u001b[0m n_samples \u001b[39m=\u001b[39m dissimilarities\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m    110\u001b[0m sim_flat \u001b[39m=\u001b[39m ((\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mtri(n_samples)) \u001b[39m*\u001b[39m dissimilarities)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m    111\u001b[0m sim_flat_w \u001b[39m=\u001b[39m sim_flat[sim_flat \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:1225\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mif\u001b[39;00m seed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m seed \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mrandom:\n\u001b[1;32m   1224\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmtrand\u001b[39m.\u001b[39m_rand\n\u001b[0;32m-> 1225\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(seed, numbers\u001b[39m.\u001b[39;49mIntegral):\n\u001b[1;32m   1226\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState(seed)\n\u001b[1;32m   1227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(seed, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState):\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[1;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_instancecheck(\u001b[39mcls\u001b[39;49m, instance)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the existing CSV into a DataFrame\n",
    "df = pd.read_csv('election_table.csv')\n",
    "\n",
    "# Search for CSV files in the directory and its subdirectories\n",
    "csv_files = glob.glob(\"../rcv_elections_database/**/*.csv\", recursive=True)\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for file_path in csv_files:\n",
    "\n",
    "    # Get the filename only\n",
    "    filename = file_path.split('/')[-1]  \n",
    "    print(file_path)\n",
    "\n",
    "    # Locate the row for the current file\n",
    "    row_indices = df[df['filename'] == filename].index\n",
    "    \n",
    "    # Check if there's a match\n",
    "    if len(row_indices) == 0:\n",
    "        print(f\"No matching row found for file: {filename}\")\n",
    "        continue  # Skip to the next iteration\n",
    "\n",
    "    row_index = row_indices[0]\n",
    "    print(row_index)\n",
    "\n",
    "    try:\n",
    "        # Get the consistency points for the election\n",
    "        points = get_consistency_points(file_path)\n",
    "            \n",
    "        # Create a list of data points\n",
    "        data_points = []\n",
    "        for key, value in points.items():\n",
    "            data_points.extend([key] * value)\n",
    "\n",
    "        # Convert to numpy array\n",
    "        data_points = np.array(data_points)\n",
    "\n",
    "        # Calculate skewness and kurtosis\n",
    "        g = skew(data_points)\n",
    "        k = kurtosis(data_points)\n",
    "\n",
    "        # Calculate KDE without plotting\n",
    "        density = gaussian_kde(data_points)\n",
    "        x_vals = np.linspace(min(data_points), max(data_points), 1000)\n",
    "        y_vals = density(x_vals)\n",
    "\n",
    "        # Identify local maxima in the KDE\n",
    "        maxima_indices = argrelextrema(y_vals, np.greater)\n",
    "\n",
    "        # Get the x-values of the maxima\n",
    "        modes = x_vals[maxima_indices]\n",
    "\n",
    "        # Check if there are at least two modes\n",
    "        if len(modes) >= 2:\n",
    "            mode1, mode2 = modes[:2]\n",
    "        else:\n",
    "            mode1, mode2 = None, None\n",
    "\n",
    "        # Split the data into two groups based on proximity to the modes\n",
    "        data_group1 = [point for point in data_points if abs(point - mode1) < abs(point - mode2)]\n",
    "        data_group2 = [point for point in data_points if abs(point - mode1) > abs(point - mode2)]\n",
    "\n",
    "        # Calculate mean and variance for each group\n",
    "        mu1, sigma1_sq = np.mean(data_group1), np.var(data_group1)\n",
    "        mu2, sigma2_sq = np.mean(data_group2), np.var(data_group2)\n",
    "\n",
    "        # Calculate Ashman's D statistic (D > 2) #! Check how it breaks\n",
    "        ashmans_D = abs(mu1 - mu2) / np.sqrt((sigma1_sq + sigma2_sq) / 2)\n",
    "\n",
    "        # Calculate Sarle's bimodality coefficient b (b > 5/9)\n",
    "        n = len(data_points)\n",
    "        sarle = (g**2 + 1) / (k + 3 * (n-1)**2 / ((n-2) * (n-3)))\n",
    "\n",
    "        # Calculate Hartigan's dip statistic ... (TODO - Ensure you have the dip_statistic function)\n",
    "        hartigan_dip = dip_statistic(data_points)\n",
    "\n",
    "        # Add new columns to the DataFrame for the current file\n",
    "        df.at[row_index, 'Ashman_D'] = ashmans_D\n",
    "        df.at[row_index, 'Sarle_coefficient'] = sarle\n",
    "        df.at[row_index, 'Hartigan_Dip'] = hartigan_dip\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error in file: {}\".format(file_path))\n",
    "        print(e)\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv('election_table_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
